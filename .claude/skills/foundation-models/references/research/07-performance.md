# 07. パフォーマンス測定

Apple Foundation Models (on-device) のレイテンシ、スループット、各条件でのパフォーマンス特性を計測した結果。

**測定環境**: macOS 26+, Apple Silicon, Release build (`swift build -c release`)
**測定方法**: `time` コマンドの real (wall clock) 値を記録

---

## 1. Cold Start レイテンシ

最初のリクエスト（モデルがメモリにロードされていない状態）。

| 試行 | プロンプト | real time | 出力トークン (推定) |
|------|-----------|-----------|---------------------|
| Cold start | "Hello" | 4.636s | ~10 |

**所見**: 初回リクエストはモデルのロードを含むため、4-15秒程度の遅延が発生する。ただしこの値は実行ごとに大きくばらつく（OS のメモリ状態やバックグラウンドプロセスに依存）。

---

## 2. Prewarm 効果

`model prewarm` コマンドでモデルを事前ロードした後のレイテンシ。

| 条件 | Prewarm 時間 | 後続 respond 時間 |
|------|-------------|-------------------|
| Prewarm 後 (1回目) | 0.022s | 7.851s |
| Prewarm 後 (2回目) | 0.022s | 3.972s |

**所見**:
- Prewarm 自体は即座に完了する（~22ms）
- ただし Prewarm 後のリクエストが Cold start より速くなるとは限らない
- Prewarm は Foundation Models フレームワークにヒントを送るだけで、モデルのフルロードを保証するものではない可能性がある
- 一般的に、連続アクセスによるウォームキャッシュの方がレイテンシ改善に効果的

---

## 3. プロンプト長によるレイテンシ変化

| プロンプト長 | プロンプト概要 | real time | 出力トークン (推定) | トークン/秒 (推定) |
|-------------|---------------|-----------|---------------------|-------------------|
| 短 (2語) | "Hi" | 15.172s | ~10 | ~0.7 |
| 中 (約20語) | OOP vs FP の説明 | 16.074s | ~450 | ~28 |
| 長 (約80語) | 5言語の詳細比較 | 40.138s | ~1200 | ~30 |

**所見**:
- 短いプロンプトでも15秒かかるケースがある（モデルロード時間を含む場合）
- 中〜長プロンプトでは、出力トークン数に比例してレイテンシが増加
- 推定生成速度は約28-30トークン/秒（ウォーム状態）
- 初回リクエスト時の遅延は主にモデルロードによるもの

---

## 4. ストリーミング vs 非ストリーミング

### 中程度の出力 (~130トークン)

| モード | real time | 出力トークン (推定) |
|--------|-----------|---------------------|
| `--stream` | 2.678s | ~130 |
| `--no-stream` | 2.745s | ~130 |

### 短い出力 (~10トークン)

| モード | real time | 出力トークン (推定) |
|--------|-----------|---------------------|
| `--stream` | 0.380s | ~10 |
| `--no-stream` | 0.379s | ~10 |

**所見**:
- 合計レイテンシ（最後のトークンまで）はストリーミング/非ストリーミングでほぼ同等
- ストリーミングの利点は Time-to-First-Token (TTFT) にある — ユーザーは最初のトークンをより早く確認できる
- 短い出力ではストリーミングと非ストリーミングの差はほぼゼロ
- オンデバイスモデルではネットワーク遅延がないため、クラウド API ほどストリーミングの恩恵は大きくない

---

## 5. Max-tokens による速度変化

| max-tokens | real time | 実際の出力トークン (推定) | トークン/秒 (推定) |
|------------|-----------|--------------------------|-------------------|
| 50 | 0.878s | ~50 | ~57 |
| 200 | 3.587s | ~200 | ~56 |
| 500 | 11.466s | ~400 | ~35 |

**所見**:
- 生成トークン数はレイテンシにほぼ線形に比例
- 推定生成速度: 35-57トークン/秒（ウォーム状態、出力長依存）
- 短い出力ほどトークンあたりのオーバーヘッドが見かけ上大きい（プロンプト処理の固定コスト）
- `--max-tokens` で出力を制限することはレイテンシ削減に直接効果的

---

## 6. 連続リクエストのスループット

同一プロンプト "What is 1+1?" を5回連続実行。

| 実行 | real time | 出力トークン (推定) |
|------|-----------|---------------------|
| Run 1 | 9.390s | ~8 |
| Run 2 | 1.282s | ~8 |
| Run 3 | 3.772s | ~8 |
| Run 4 | 8.099s | ~8 |
| Run 5 | 2.119s | ~8 |

| 統計 | 値 |
|------|-----|
| 平均 | 4.932s |
| 最小 | 1.282s |
| 最大 | 9.390s |
| 中央値 | 3.772s |

**所見**:
- レイテンシのばらつきが非常に大きい（1.3s〜9.4s）
- 初回が最も遅く、2回目が最速 — モデルのメモリキャッシュ効果が顕著
- しかし3回目以降もばらつきが大きく、一貫したパフォーマンスは保証されない
- OS レベルのリソース競合（他のプロセス、メモリ圧力）が影響している可能性

---

## 7. 構造化出力のパフォーマンス

| スキーマ複雑度 | real time | 出力トークン (推定) |
|---------------|-----------|---------------------|
| Simple (3フィールド) | 3.595s | ~15 |
| Complex (ネスト配列) | 8.738s | ~80 |

**所見**:
- 構造化出力は通常のテキスト生成より若干遅い傾向
- スキーマの複雑さ（ネスト・配列）に応じてレイテンシが増加
- JSON スキーマバリデーションのオーバーヘッドは小さいが、制約付き生成のため生成速度自体がやや低下

---

## 8. ツール呼び出し時のパフォーマンス

| 条件 | real time | 備考 |
|------|-----------|------|
| ツールなし | 0.355s | 直接回答 |
| `--tool shell --tool-approval auto` | 12.128s | ツール呼び出し+実行+応答生成 |
| `--tool file-read --tool-approval auto` | 7.020s | ツール呼び出し+実行+応答生成 |

**所見**:
- ツール呼び出しは大幅なレイテンシ増加を伴う（ツールなし比で 20-34倍）
- ツール呼び出し時のレイテンシ内訳:
  1. ツール呼び出し判断の生成
  2. ツール実行
  3. ツール結果を踏まえた最終応答の生成
- 3段階の推論が必要なため、単純なリクエストに比べて大幅に時間がかかる
- ツールが不要なクエリには `--tool` を付けないことが重要

---

## パフォーマンスガイドライン

### 典型的なレイテンシ範囲

| シナリオ | 典型的なレイテンシ |
|---------|-------------------|
| Cold start (初回リクエスト) | 5-15秒 |
| Warm リクエスト (短い出力) | 0.3-2秒 |
| Warm リクエスト (中程度の出力) | 2-5秒 |
| Warm リクエスト (長い出力) | 10-40秒 |
| 構造化出力 (シンプル) | 2-4秒 |
| 構造化出力 (複雑) | 5-10秒 |
| ツール呼び出し含む | 7-15秒 |

### パフォーマンスに影響する主要因

1. **モデルのメモリ状態**: 最も大きな影響要因。初回ロードは数秒〜十数秒かかるが、メモリにキャッシュされた状態では数百ミリ秒で応答開始
2. **出力トークン数**: レイテンシに線形に比例。`--max-tokens` による制限が直接的に効果的
3. **ツール呼び出し**: 複数回の推論ラウンドトリップが発生し、大幅なレイテンシ増加
4. **スキーマ複雑度**: 構造化出力では制約付き生成のオーバーヘッドが発生
5. **OS リソース状態**: 同一条件でもばらつきが大きく、他プロセスの影響を受ける

### 最適化のヒント

1. **`--max-tokens` を積極的に使う**: 必要最小限のトークン数を指定することで、レイテンシを大幅に削減できる
2. **不要なツールを登録しない**: ツールが登録されているとモデルがツール呼び出しを検討するオーバーヘッドが発生する。必要な時だけ `--tool` を指定する
3. **ストリーミングで UX 改善**: 合計レイテンシは変わらないが、`--stream` で TTFT を改善しユーザー体感を向上できる
4. **連続使用で Warm 状態を維持**: セッション機能 (`session respond`) を使うことで、モデルが Warm 状態を保ちやすい
5. **Prewarm は補助的**: `model prewarm` は確実な効果を保証しないが、起動前の予備的なウォームアップとして利用可能
6. **構造化出力のスキーマは必要最小限に**: フィールド数やネストの深さを減らすことで生成速度が向上する
7. **プロンプト長は影響小**: 入力プロンプトの長さよりも出力トークン数の方がレイテンシへの影響が大きい

### 推定生成速度

- **ウォーム状態の推定速度**: 28-57 トークン/秒
- **平均的な推定速度**: ~35 トークン/秒
- オンデバイスモデルのため、ネットワーク遅延はゼロだが、生成速度自体はクラウド API に比べると控えめ

### 注意事項

- 計測値はシステム状態により大きくばらつく（同一条件で 3-10倍の差）
- `time` コマンドにはプロセス起動・終了のオーバーヘッドも含まれる
- Foundation Models はシステムリソース（NPU/GPU）を共有するため、他のアプリの使用状況が影響する
- バッテリー残量や電源接続状態もパフォーマンスに影響する可能性がある
